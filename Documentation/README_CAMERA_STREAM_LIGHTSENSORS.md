# Wheels: Raspberry Pi Camera Streaming to Unity

This system streams video from a Raspberry Pi camera to a Unity-based application on a PC using RTSP and disk-based frame sharing. It builds on the distributed WebSocket architecture already in place in the Wheels project, adding live vision support.

---

## ğŸ“ Architecture Overview

```
[Raspberry Pi]
â”œâ”€ mediamtx.service (RTSP Server)
â””â”€ camera-stream.service (libcamera-vid + ffmpeg)
     â†’ Streams RTSP to localhost:8554

[PC]
â”œâ”€ Unity
â”‚  â”œâ”€ StartPythonCapture.cs  â†’ Starts Python
â”‚  â””â”€ LiveFrameViewer.cs     â†’ Loads image from disk
â””â”€ process_incoming_frames.py (RTSP client â†’ writes output_0.jpg ... output_4.jpg)
```

---

## ğŸ§  Design Summary

| Component              | Purpose                                          |
|------------------------|--------------------------------------------------|
| RTSP via MediaMTX      | Lightweight video stream server                  |
| libcamera-vid + ffmpeg | Low-latency H.264 encoder                        |
| Python Frame Grabber   | Extracts frames and writes to disk               |
| Unity                  | Displays frames in real time via Texture2D       |
| Systemd Services       | Ensure all components start automatically        |

---

## âš™ï¸ Scripts and Services

### camera-stream.service (Raspberry Pi)

Starts the camera and pipes H.264 video to MediaMTX:

```bash
libcamera-vid -t 0 --width 640 --height 480 --framerate 30 \
  --codec h264 --inline --profile baseline --flush -o - | \
ffmpeg -f h264 -i - -vcodec copy -f rtsp rtsp://localhost:8554/stream
```

---

### mediamtx.service (Raspberry Pi)

Starts the RTSP server using a config at:
```
/home/gbrouwer/Configs/mediamtx.yml
```

---

### process_incoming_frames.py (PC)

- Connects to RTSP stream from Raspberry Pi
- Extracts frames using ffmpeg
- Writes last 5 frames as:
  - `output_0.jpg`
  - `output_1.jpg`
  - ...
  - `output_4.jpg`

---

### StartPythonCapture.cs (Unity)

- Launches `process_incoming_frames.py` using a real `python.exe`
- Can be configured via inspector

---

### LiveFrameViewer.cs (Unity)

- Reads `output_2.jpg` (or similar) at 30 FPS
- Applies frame to a `RawImage`
- Avoids read/write collisions by staying behind the current write index

---

## ğŸ”§ Performance Summary

| Step                    | Time per frame |
|-------------------------|----------------|
| Encode (Pi)             | ~10â€“20ms       |
| Network (RTSP)          | <5ms           |
| Decode + Save (Python)  | ~10â€“15ms       |
| Load + Display (Unity)  | ~5â€“10ms        |
| **Total Latency**       | **~150â€“250ms** |

---

## ğŸš€ Services Enabled on Boot

```bash
sudo systemctl enable mediamtx.service
sudo systemctl enable camera-stream.service
```

---

## âœ… Current Resolution

```
640 Ã— 480 px @ 30 fps
JPEG compression on disk (~20â€“50 KB per frame)
```

---

## ğŸ“Œ Future Ideas

- Switch to raw .bmp or binary formats
- Directly decode RTSP in Unity (via plugin)
- Use frame timestamps for sensor sync
- Add camera command channel via WebSocket

